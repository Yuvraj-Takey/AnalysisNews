
[ 2024-09-10 14:41:15,551 ] - DEBUG - root - main.py:17 - Initiated Preprocessing Module

[ 2024-09-10 14:41:15,552 ] - DEBUG - root - processDataIngestion.py:11 - Document Ingestion class initialized

[ 2024-09-10 14:41:21,935 ] - DEBUG - root - processDataIngestion.py:33 - Successfully loaded the input file to the memory

[ 2024-09-10 14:41:21,936 ] - DEBUG - root - processEdit.py:10 - Process Edit Message class initialized

[ 2024-09-10 14:41:21,936 ] - DEBUG - root - processJSON.py:25 - JSON Pre-Processing class initiated

[ 2024-09-10 14:41:21,937 ] - DEBUG - root - utils.py:31 - [INFO] : Loading the configuration data

[ 2024-09-10 14:41:21,947 ] - INFO - root - utils.py:37 - Config Yaml loaded succesfully.

[ 2024-09-10 14:41:21,997 ] - DEBUG - root - processEdit.py:85 - Operation on-line extraction has initiated

[ 2024-09-10 14:41:21,998 ] - DEBUG - root - processEdit.py:32 - Started operation on line level adjustment

[ 2024-09-10 14:41:21,998 ] - DEBUG - root - processEdit.py:67 - Forwarding JSON object for futher pre-processing task

[ 2024-09-10 14:41:21,998 ] - DEBUG - root - processJSON.py:386 - Dealing with missing columns and sheets

[ 2024-09-10 14:41:22,014 ] - DEBUG - root - processJSON.py:55 - Started extraction of claim IDs from the input file

[ 2024-09-10 14:41:22,017 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,019 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,031 ] - DEBUG - root - processJSON.py:308 - Working on Hippa Attribute

[ 2024-09-10 14:41:22,041 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,045 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,087 ] - DEBUG - root - processJSON.py:254 - max date replacement task is started

[ 2024-09-10 14:41:22,090 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,092 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,101 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,104 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,190 ] - DEBUG - root - processJSON.py:336 - Dealing with Raw data from COB

[ 2024-09-10 14:41:22,191 ] - DEBUG - root - processJSON.py:254 - max date replacement task is started

[ 2024-09-10 14:41:22,194 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,195 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,243 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,244 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,256 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,257 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,282 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,282 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,317 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,318 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,381 ] - DEBUG - root - processJSON.py:87 - Data persistance is started

[ 2024-09-10 14:41:22,390 ] - INFO - root - processJSON.py:101 - Data JSON is stored at the location : C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\artifacts\output\24B121111110_wm_invalidproviderselection.json

[ 2024-09-10 14:41:22,392 ] - DEBUG - root - processEdit.py:32 - Started operation on line level adjustment

[ 2024-09-10 14:41:22,393 ] - DEBUG - root - processEdit.py:67 - Forwarding JSON object for futher pre-processing task

[ 2024-09-10 14:41:22,393 ] - DEBUG - root - processJSON.py:386 - Dealing with missing columns and sheets

[ 2024-09-10 14:41:22,422 ] - DEBUG - root - processJSON.py:55 - Started extraction of claim IDs from the input file

[ 2024-09-10 14:41:22,425 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,429 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,445 ] - DEBUG - root - processJSON.py:308 - Working on Hippa Attribute

[ 2024-09-10 14:41:22,452 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,454 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,484 ] - DEBUG - root - processJSON.py:254 - max date replacement task is started

[ 2024-09-10 14:41:22,487 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,489 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,502 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,506 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,630 ] - DEBUG - root - processJSON.py:336 - Dealing with Raw data from COB

[ 2024-09-10 14:41:22,632 ] - DEBUG - root - processJSON.py:254 - max date replacement task is started

[ 2024-09-10 14:41:22,642 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,644 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,732 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,734 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,747 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,748 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,777 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,779 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,821 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 14:41:22,823 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 14:41:22,924 ] - DEBUG - root - processJSON.py:87 - Data persistance is started

[ 2024-09-10 14:41:22,932 ] - INFO - root - processJSON.py:101 - Data JSON is stored at the location : C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\artifacts\output\24B121111110_wm_invalidproviderselectiononline1.json

[ 2024-09-10 14:41:22,934 ] - DEBUG - root - dataFiltration.py:10 - filterData class initialized

[ 2024-09-10 14:41:22,951 ] - DEBUG - root - dataFiltration.py:222 - Got ['24B121111110_wm_invalidproviderselection.json', '24B121111110_wm_invalidproviderselectiononline1.json'] for filtering

[ 2024-09-10 14:41:22,954 ] - DEBUG - root - dataFiltration.py:234 - Started filtering 24B121111110_wm_invalidproviderselection

[ 2024-09-10 14:41:22,954 ] - DEBUG - root - dataFiltration.py:165 - Started filtering and appying 2 filter/s

[ 2024-09-10 14:41:22,965 ] - ERROR - root - main.py:42 - There seems to be a issue in Preprocessing - Traceback (most recent call last):
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 86, in extractFilterVariables
    actualValue = dataFrames['24B121111110'][valueSheet][valueColumn].values[0] # getting the actual value based on referred sheet and columm
TypeError: list indices must be integers or slices, not str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 171, in filterInputFile
    filterSheet, filterColumn, operator, actualValue = self.extractFilterVariables(dataFrames = dataFrames, filterdata = option) # getting filter variables
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 91, in extractFilterVariables
    raise Exception()
Exception

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 242, in getFilteredInputFile
    dataFrames = self.filterInputFile(inputFile, filters)
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 174, in filterInputFile
    raise Exception()
Exception

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\main.py", line 31, in inputPreprocessUnit
    filterObj.getFilteredInputFile(jsonFileName)
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 252, in getFilteredInputFile
    raise Exception()
Exception

