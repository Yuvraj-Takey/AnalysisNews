
[ 2024-09-10 19:14:42,996 ] - DEBUG - root - main.py:17 - Initiated Preprocessing Module

[ 2024-09-10 19:14:42,996 ] - DEBUG - root - processDataIngestion.py:11 - Document Ingestion class initialized

[ 2024-09-10 19:14:48,664 ] - DEBUG - root - processDataIngestion.py:33 - Successfully loaded the input file to the memory

[ 2024-09-10 19:14:48,665 ] - DEBUG - root - processEdit.py:10 - Process Edit Message class initialized

[ 2024-09-10 19:14:48,665 ] - DEBUG - root - processJSON.py:25 - JSON Pre-Processing class initiated

[ 2024-09-10 19:14:48,665 ] - DEBUG - root - utils.py:31 - [INFO] : Loading the configuration data

[ 2024-09-10 19:14:48,679 ] - INFO - root - utils.py:37 - Config Yaml loaded succesfully.

[ 2024-09-10 19:14:48,733 ] - DEBUG - root - processEdit.py:85 - Operation on-line extraction has initiated

[ 2024-09-10 19:14:48,735 ] - DEBUG - root - processEdit.py:32 - Started operation on line level adjustment

[ 2024-09-10 19:14:48,736 ] - DEBUG - root - processEdit.py:67 - Forwarding JSON object for futher pre-processing task

[ 2024-09-10 19:14:48,736 ] - DEBUG - root - processJSON.py:401 - Dealing with missing columns and sheets

[ 2024-09-10 19:14:48,796 ] - DEBUG - root - processJSON.py:55 - Started extraction of claim IDs from the input file

[ 2024-09-10 19:14:48,800 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:48,807 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:48,830 ] - DEBUG - root - processJSON.py:323 - Working on Hippa Attribute

[ 2024-09-10 19:14:48,839 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:48,851 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:48,900 ] - DEBUG - root - processJSON.py:269 - max date replacement task is started

[ 2024-09-10 19:14:48,906 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:48,913 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:48,929 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:48,942 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,149 ] - DEBUG - root - processJSON.py:351 - Dealing with Raw data from COB

[ 2024-09-10 19:14:49,152 ] - DEBUG - root - processJSON.py:269 - max date replacement task is started

[ 2024-09-10 19:14:49,157 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:49,165 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,279 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:49,285 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,310 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:49,317 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,370 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:49,377 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,454 ] - DEBUG - root - processJSON.py:205 - Data cleaning task is started

[ 2024-09-10 19:14:49,461 ] - DEBUG - root - processJSON.py:117 - Data type conversion task is started

[ 2024-09-10 19:14:49,568 ] - DEBUG - root - processJSON.py:87 - Data persistance is started

[ 2024-09-10 19:14:49,579 ] - INFO - root - processJSON.py:101 - Data JSON is stored at the location : C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\artifacts\output\24B121111110_wm_invalidproviderselection.json

[ 2024-09-10 19:14:49,580 ] - DEBUG - root - dataFiltration.py:10 - filterData class initialized

[ 2024-09-10 19:14:49,594 ] - DEBUG - root - dataFiltration.py:234 - Got ['24B121111110_wm_invalidproviderselection.json'] for filtering

[ 2024-09-10 19:14:49,608 ] - DEBUG - root - dataFiltration.py:246 - Started filtering 24B121111110_wm_invalidproviderselection

[ 2024-09-10 19:14:49,608 ] - DEBUG - root - dataFiltration.py:179 - Started filtering and appying 2 filter/s

[ 2024-09-10 19:14:49,636 ] - DEBUG - root - dataFiltration.py:136 - applyFilter initialized for input1.providerdetails.npi == 

[ 2024-09-10 19:14:49,645 ] - ERROR - root - main.py:42 - There seems to be a issue in Preprocessing - Traceback (most recent call last):
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\main.py", line 31, in inputPreprocessUnit
    filterObj.getFilteredInputFile(jsonFileName)
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 254, in getFilteredInputFile
    dataFrames = self.filterInputFile(inputFile, filters)
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 186, in filterInputFile
    dataFrames = self.applyFilter(dataFrames, filterSheet, filterColumn, operator, actualValue) # applying a filter
  File "C:\Users\2332220\OneDrive - Cognizant\Desktop\GenAI_24\0_Experimentals\0_Expr_Test\1_EXCEL_JSON\1_Input_PreProcessing\components\dataFiltration.py", line 142, in applyFilter
    date_pattern = re.compile(r"^\d{4}-([0]?[1-9]|1[012])-([0]?[1-9]|[12][0-9]|3[01])$")
NameError: name 're' is not defined

